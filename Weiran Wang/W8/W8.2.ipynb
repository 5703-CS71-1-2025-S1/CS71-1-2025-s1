{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3093df6b-3da2-446d-a3f4-46e8c552386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LLM + PSO Optimization System (Credit Card + MLPClassifier) ===\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pyswarms.single.global_best import GlobalBestPSO\n",
    "\n",
    "# --- Step 1: Setup ---\n",
    "load_dotenv(\"OPENAI_API_KEY.env\")\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# --- Step 2: Load and Preprocess Dataset ---\n",
    "df = pd.read_excel(\"default of credit card clients.xls\", header=1)\n",
    "X = df.drop(columns=[\"ID\", \"default payment next month\"]).values\n",
    "y = df[\"default payment next month\"].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.25, random_state=42)\n",
    "\n",
    "# --- Step 3: Define Objective Function ---\n",
    "def mlp_objective(params):\n",
    "    hidden, lr, dropout, l2 = params\n",
    "    hidden = int(hidden)\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(hidden,), learning_rate_init=lr, alpha=l2,\n",
    "                        early_stopping=True, max_iter=300, random_state=42)\n",
    "    try:\n",
    "        clf.fit(X_train, y_train)\n",
    "        probas = clf.predict_proba(X_val)[:, 1]\n",
    "        auc = roc_auc_score(y_val, probas)\n",
    "        return -auc\n",
    "    except:\n",
    "        return 1.0\n",
    "\n",
    "# --- Step 4: PSO Execution Function ---\n",
    "def run_pso(bounds, num_particles=10, max_iter=5):\n",
    "    print(\"üîß [Executor Agent] Running PSO with bounds:\", bounds)\n",
    "    logs = []\n",
    "    def fitness_fn(X):\n",
    "        return np.array([mlp_objective(p) for p in X])\n",
    "\n",
    "    optimizer = GlobalBestPSO(n_particles=num_particles, dimensions=4, options={'c1': 1.5, 'c2': 1.5, 'w': 0.5}, bounds=bounds)\n",
    "    best_cost, best_pos = optimizer.optimize(fitness_fn, iters=max_iter)\n",
    "    all_particles = optimizer.pos_history[-1]\n",
    "    aucs = [-mlp_objective(p) for p in all_particles]\n",
    "    logs.extend(zip(all_particles, aucs))\n",
    "    print(\"‚úÖ [Executor Agent] Best AUC this round:\", -best_cost)\n",
    "    return best_pos, best_cost, logs\n",
    "\n",
    "# --- Step 5: GPT Suggestion ---\n",
    "def query_gpt_with_logs(logs, round_id):\n",
    "    print(\"üß† [Creator Agent] Analyzing logs and generating new search bounds...\")\n",
    "    top5 = sorted(logs, key=lambda x: -x[1])[:5]\n",
    "    log_str = \"\\n\".join([f\"{i+1}. HP={p} ‚Üí AUC={a:.4f}\" for i, (p, a) in enumerate(top5)])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "IMPORTANT: In this round, your goal is to not only maximize AUC, but also reduce fluctuation across rounds.\n",
    "Try to narrow the search ranges if the top configurations are consistent.\n",
    "Avoid wide repetitive ranges like [32,128] unless necessary.\n",
    "\n",
    "You are a task creation AI expert in machine learning that is required to optimize the model‚Äôs hyperparameter settings to accomplish the final objective.\n",
    "\n",
    "Model Info: MLPClassifier\n",
    "Dataset Info: UCI Credit Default Dataset (23 numeric features, binary classification)\n",
    "Hyperparameters:\n",
    "- hidden: number of neurons\n",
    "- lr: learning rate\n",
    "- dropout: dropout rate\n",
    "- l2: L2 regularization\n",
    "\n",
    "Here are the top 5 historical training logs:\n",
    "{log_str}\n",
    "\n",
    "Use the following format:\n",
    "Objective: your goal\n",
    "Thought: your reasoning\n",
    "Action: Final Answer\n",
    "Final Answer: JSON with min/max ranges for each hyperparameter\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    text = response.choices[0].message.content.strip()\n",
    "    print(\"üì§ [Creator Agent] Full response:\\n\", text)\n",
    "    with open(\"gpt_trace_round.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"\\n==== Round {round_id+1} GPT Response ====\\n\")\n",
    "        f.write(text + \"\\n\")\n",
    "\n",
    "    try:\n",
    "        match = re.search(r\"Final Answer:\\s*(\\{.*\\})\", text, re.DOTALL)\n",
    "        if match:\n",
    "            answer_str = match.group(1)\n",
    "            suggestion = json.loads(answer_str)\n",
    "\n",
    "            # ‚úÖ Clamp unstable ranges to improve convergence\n",
    "            suggestion[\"dropout\"][\"min\"] = max(0.05, suggestion[\"dropout\"][\"min\"])\n",
    "            suggestion[\"dropout\"][\"max\"] = min(0.5, suggestion[\"dropout\"][\"max\"])\n",
    "            suggestion[\"l2\"][\"min\"] = max(1e-5, suggestion[\"l2\"][\"min\"])\n",
    "            suggestion[\"l2\"][\"max\"] = min(0.01, suggestion[\"l2\"][\"max\"])\n",
    "            return suggestion\n",
    "        else:\n",
    "            raise ValueError(\"No Final Answer block found.\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è Parsing failed:\", e)\n",
    "        return {\n",
    "            \"hidden\": {\"min\": 64, \"max\": 128},\n",
    "            \"lr\": {\"min\": 0.0001, \"max\": 0.01},\n",
    "            \"dropout\": {\"min\": 0.0, \"max\": 0.5},\n",
    "            \"l2\": {\"min\": 0.0001, \"max\": 0.01}\n",
    "        }\n",
    "\n",
    "# --- Step 6: Baseline Comparison (no GPT) ---\n",
    "baseline_auc_all = []\n",
    "baseline_n_trials = 5\n",
    "baseline_bounds = ([32, 0.0001, 0.0, 0.00001], [128, 0.01, 0.5, 0.1])\n",
    "\n",
    "for trial in range(baseline_n_trials):\n",
    "    trial_auc = []\n",
    "    for _ in range(10):\n",
    "        _, cost, _ = run_pso(baseline_bounds)\n",
    "        trial_auc.append(-cost)\n",
    "    baseline_auc_all.append(trial_auc)\n",
    "\n",
    "baseline_auc_all = np.array(baseline_auc_all)\n",
    "baseline_auc_mean = np.mean(baseline_auc_all, axis=0)\n",
    "baseline_auc_std = np.std(baseline_auc_all, axis=0)\n",
    "\n",
    "# --- Step 7: Main Loop ---\n",
    "def run_llm_pso_trials(n_trials=5):\n",
    "    all_trials = []\n",
    "    global bound_records, log_records, search_bounds_traj\n",
    "    bound_records = []\n",
    "    log_records = []\n",
    "    search_bounds_traj = []\n",
    "\n",
    "    for trial in range(n_trials):\n",
    "        print(f\"\n",
    "üß™ Running LLM+PSO Trial {trial+1}...\")\n",
    "        trial_auc = []\n",
    "        bounds = ([32, 0.0001, 0.0, 0.00001], [128, 0.01, 0.5, 0.1])\n",
    "        for round_id in range(10):\n",
    "            print(f\"==================== Round {round_id+1} ====================\")\n",
    "            best_pos, best_cost, logs = run_pso(bounds)\n",
    "            trial_auc.append(-best_cost)\n",
    "            suggestion = query_gpt_with_logs(logs, round_id)\n",
    "            print(\"üí° [Creator Agent] Suggested bounds:\", suggestion)\n",
    "\n",
    "            # record bound\n",
    "            bound_records.append({\n",
    "                \"round\": round_id + 1,\n",
    "                \"hidden_min\": suggestion[\"hidden\"][\"min\"],\n",
    "                \"hidden_max\": suggestion[\"hidden\"][\"max\"],\n",
    "                \"lr_min\": suggestion[\"lr\"][\"min\"],\n",
    "                \"lr_max\": suggestion[\"lr\"][\"max\"],\n",
    "                \"dropout_min\": suggestion[\"dropout\"][\"min\"],\n",
    "                \"dropout_max\": suggestion[\"dropout\"][\"max\"],\n",
    "                \"l2_min\": suggestion[\"l2\"][\"min\"],\n",
    "                \"l2_max\": suggestion[\"l2\"][\"max\"]\n",
    "            })\n",
    "\n",
    "            # record log\n",
    "            log_records.append({\n",
    "                \"round\": round_id + 1,\n",
    "                \"auc\": -best_cost,\n",
    "                \"hidden\": int(best_pos[0]),\n",
    "                \"lr\": best_pos[1],\n",
    "                \"dropout\": best_pos[2],\n",
    "                \"l2\": best_pos[3]\n",
    "            })\n",
    "\n",
    "            search_bounds_traj.append(suggestion)\n",
    "\n",
    "            keys = ['hidden', 'lr', 'dropout', 'l2']\n",
    "            bounds = (\n",
    "                [suggestion[k]['min'] for k in keys],\n",
    "                [suggestion[k]['max'] for k in keys]\n",
    "            )\n",
    "\n",
    "        all_trials.append(trial_auc)\n",
    "\n",
    "        # ‚úÖ Store final best parameters for use in final evaluation\n",
    "        if trial == n_trials - 1:\n",
    "            global best_params\n",
    "            best_params = best_pos\n",
    "    return np.array(all_trials)\n",
    "\n",
    "llm_auc_all = run_llm_pso_trials(n_trials=5)\n",
    "llm_auc_mean = np.mean(llm_auc_all, axis=0)\n",
    "llm_auc_std = np.std(llm_auc_all, axis=0)\n",
    "\n",
    "final_hidden, final_lr, final_dropout, final_l2 = map(float, best_params)\n",
    "final_hidden = int(final_hidden)\n",
    "final_clf = MLPClassifier(hidden_layer_sizes=(final_hidden,), learning_rate_init=final_lr, alpha=final_l2,\n",
    "                          early_stopping=True, max_iter=300, random_state=42)\n",
    "final_clf.fit(X_trainval, y_trainval)\n",
    "final_preds = final_clf.predict_proba(X_test)[:, 1]\n",
    "final_auc = roc_auc_score(y_test, final_preds)\n",
    "print(f\"\\nüéØ Final Test AUC: {final_auc:.4f}\")\n",
    "\n",
    "# --- Step 8: AUC Convergence Visualization ---\n",
    "plt.figure()\n",
    "plt.errorbar(range(1, 11), llm_auc_mean, yerr=llm_auc_std, label='LLM+PSO (mean ¬± std)', marker='o', capsize=3)\n",
    "plt.errorbar(range(1, 11), baseline_auc_mean, yerr=baseline_auc_std, label='PSO only (mean ¬± std)', marker='x', linestyle='--', capsize=3)\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Best AUC\")\n",
    "plt.title(\"AUC Convergence: LLM+PSO vs PSO-only\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, len(all_auc)+1), all_auc, marker='o')\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Best AUC\")\n",
    "plt.title(\"AUC Convergence across Rounds (LLM+PSO)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Step 9: Save Results to CSV ---\n",
    "pd.DataFrame(log_records).to_csv(\"round_best_results.csv\", index=False)\n",
    "pd.DataFrame(bound_records).to_csv(\"round_search_bounds.csv\", index=False)\n",
    "\n",
    "# --- Step 10: (Removed duplicate Baseline block above)\n",
    "\n",
    "print(\" Summary Statistics:\")\n",
    "print(\"LLM+PSO AUC: mean = {:.4f}, std = {:.4f}\".format(np.mean(all_auc), np.std(all_auc)))\n",
    "print(\"Baseline PSO AUC: mean = {:.4f}, std = {:.4f}\".format(np.mean(baseline_auc_all), np.std(baseline_auc_all)))\n",
    "\n",
    "# --- Step 11: LLM-Guided Search Range Width Analysis ---\n",
    "width_records = []\n",
    "for bound in bound_records:\n",
    "    width_records.append({\n",
    "        \"round\": bound[\"round\"],\n",
    "        \"hidden_width\": bound[\"hidden_max\"] - bound[\"hidden_min\"],\n",
    "        \"lr_width\": bound[\"lr_max\"] - bound[\"lr_min\"],\n",
    "        \"dropout_width\": bound[\"dropout_max\"] - bound[\"dropout_min\"],\n",
    "        \"l2_width\": bound[\"l2_max\"] - bound[\"l2_min\"]\n",
    "    })\n",
    "width_df = pd.DataFrame(width_records)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(width_df[\"round\"], width_df[\"hidden_width\"], label=\"hidden\")\n",
    "plt.plot(width_df[\"round\"], width_df[\"lr_width\"], label=\"lr\")\n",
    "plt.plot(width_df[\"round\"], width_df[\"dropout_width\"], label=\"dropout\")\n",
    "plt.plot(width_df[\"round\"], width_df[\"l2_width\"], label=\"l2\")\n",
    "plt.xlabel(\"Round\")\n",
    "plt.ylabel(\"Search Range Width\")\n",
    "plt.title(\"LLM-Guided Hyperparameter Range Shrinking\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Step 12: Trajectory Visualization ---\n",
    "x_vals, y_vals = [], []\n",
    "for s in search_bounds_traj:\n",
    "    x = (s['hidden']['min'] + s['hidden']['max']) / 2\n",
    "    y = (s['lr']['min'] + s['lr']['max']) / 2\n",
    "    x_vals.append(x)\n",
    "    y_vals.append(y)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x_vals, y_vals, marker='o')\n",
    "for i, (x, y) in enumerate(zip(x_vals, y_vals)):\n",
    "    plt.text(x, y, str(i+1), fontsize=8)\n",
    "plt.title(\"Trajectory of GPT-guided Search Ranges (hidden vs lr)\")\n",
    "plt.xlabel(\"Hidden Layer Size (center)\")\n",
    "plt.ylabel(\"Learning Rate (center)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e1374d-77cb-478e-9776-9867cc975325",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
